"""Prompt templates for LLM interactions."""

ISSUE_CATEGORIZATION_PROMPT = """You are an issue classifier for open-source repositories.
Analyze the following GitHub issue and provide a JSON response with:
1. category: One of {categories}
2. complexity: An integer from 1-10 (1=trivial, 10=architectural change)
3. solvability: A float from 0-1 (probability of successful automated fix)
4. breaking_change: Boolean (whether this change breaks public API)
5. test_required: Boolean (whether tests should be created/modified)

Issue:
Title: {title}
Body: {body}
Labels: {labels}
Comments: {comment_count}
Reactions: {reactions}

Respond only with valid JSON, no markdown.
"""


ISSUE_COMPLEXITY_PROMPT = """Estimate the complexity of implementing a fix for this GitHub issue.

Consider:
- Number of files that likely need changes
- Scope of changes (single function vs module vs cross-module)
- Need for tests
- Risk of breaking existing functionality
- Dependencies on other systems

Issue:
Repository: {repo}
Title: {title}
Body: {body}

Provide a JSON response with:
{{
  "complexity": 1-10,
  "estimated_hours": number,
  "affected_files": ["file1", "file2"],
  "risk_level": "low" | "medium" | "high" | "critical",
  "reasoning": "brief explanation"
}}
"""


CODE_GENERATION_PROMPT = """Generate a fix for the following GitHub issue.

Repository: {repo}
Language: {language}

Issue:
Title: {title}
Description: {description}

Requirements:
{requirements}

Generate a complete, production-ready solution that:
1. Follows the repository's coding style
2. Includes appropriate error handling
3. Has type hints where applicable
4. Includes necessary imports

Provide your response as a JSON object with:
{{
  "explanation": "step-by-step explanation of the fix",
  "files": [
    {{
      "path": "path/to/file.ext",
      "original_content": "original file content",
      "new_content": "new file content with changes",
      "description": "what changed in this file"
    }}
  ],
  "tests": [
    {{
      "path": "path/to/test_file.ext",
      "content": "test file content"
    }}
  ]
}}
"""


PR_DESCRIPTION_TEMPLATE = """## Summary
{summary}

## Changes
- **Files modified**: {file_count}
- **Lines changed**: {lines_changed}
- **Complexity**: {complexity}/10

### Affected files
{files_list}

## Tests
{tests_status}

## Auto-Merge
This PR is configured to auto-merge when all CI checks pass.

**Requirements for auto-merge:**
- [x] Syntax validated
- [x] Risk level: {risk_level}
- [x] Complexity: {complexity}/10
{tests_check}

---
*Generated by GlobalLM - LLM-powered open source contribution*
"""


def format_issue_categorization_prompt(
    title: str,
    body: str,
    labels: list[str],
    comment_count: int = 0,
    reactions: dict[str, int] | None = None,
    categories: str = "critical_security, bug_critical, bug, feature, enhancement, documentation, style, refactor, performance, tests",
) -> str:
    """Format the issue categorization prompt."""
    return ISSUE_CATEGORIZATION_PROMPT.format(
        title=title,
        body=body or "No description provided.",
        labels=", ".join(labels) if labels else "none",
        comment_count=comment_count,
        reactions=str(reactions) if reactions else "{}",
        categories=categories,
    )


def format_complexity_prompt(repo: str, title: str, body: str) -> str:
    """Format the complexity estimation prompt."""
    return ISSUE_COMPLEXITY_PROMPT.format(
        repo=repo,
        title=title,
        body=body or "No description provided.",
    )


def format_code_generation_prompt(
    repo: str,
    language: str,
    title: str,
    description: str,
    requirements: str,
) -> str:
    """Format the code generation prompt."""
    return CODE_GENERATION_PROMPT.format(
        repo=repo,
        language=language,
        title=title,
        description=description,
        requirements=requirements,
    )
